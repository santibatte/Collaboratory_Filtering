{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Integrantes\n",
    "* Santiago\n",
    "* Jose Reyes 142207\n",
    "* Patricia\n",
    "* Yedam Fortiz 119523"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de paqueteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import random as r\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import ndcg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de Informacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = pd.read_csv(\"links_small.csv\")\n",
    "ratings = pd.read_csv(\"ratings_small.csv\")\n",
    "ratings = ratings.drop(\"timestamp\",axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Por ahora consideraremos únicamente 1500 lineas de ratings, no los 100,000 registros ya que el algoritmo no está optimizado para una base de datos tan grande"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test = train_test_split(ratings.head(1500),test_size=0.3,random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_wide = X_train.pivot_table(index = 'userId',\n",
    "                                   columns = 'movieId',\n",
    "                                   values = 'rating')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creacion de matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "links_values = np.array(links)\n",
    "links_features = np.array(links.columns)\n",
    "ratings_values = np.array(ratings_wide)\n",
    "ratings_features = np.array(ratings_wide.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funcion de costo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\large J(X)  =  \\frac{1}{2} \\sum_{(a,i \\in D)} (Y_{ai} - [UV^T]_{ai} )^2 + \\frac{\\lambda}{2} \\sum_{a=1}^n\\sum_{j=1}^k U_{aj}^2 + \\frac{\\lambda}{2} \\sum_{i=1}^m\\sum_{j=1}^k V_{ij}^2  $$\n",
    "\n",
    "* Seleccionamos $V$ al azar y la dejamos fija y optimizamos con respecto a $U$\n",
    "* Una vez actualizada la $U$, la dejamos fija y optimizamos con respecto a $V$\n",
    "* Repetimos hasta que converja (variaciones entre las estimaciones de los vectores es pequeña) (optimo local)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Minimizacion Alternada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradiente_U (Y,U,V,k,lambda_):\n",
    "    \n",
    "    if k!=1:\n",
    "        U_V = U.dot(V.T)\n",
    "    else:\n",
    "        U_V = np.outer(U,V)\n",
    "    \n",
    "    na = np.isnan(Y)\n",
    "    \n",
    "    #Tratamiento especial NA\n",
    "    #gradiente = -dot_na(Y-U_V, V) + lambda_*U\n",
    "    gradiente = -(Y-U_V)@V + lambda_*U\n",
    "    \n",
    "    return gradiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradiente_V (Y,U,V,k,lambda_):\n",
    "    \n",
    "    if k!=1:\n",
    "        U_V = U.dot(V.T)\n",
    "    else:\n",
    "        U_V = np.outer(U,V)\n",
    "    \n",
    "    na = np.isnan(Y)\n",
    "    \n",
    "    #Tratamiento especial NA\n",
    "    #gradiente = -dot_na((Y-U_V).T, U) + lambda_*V\n",
    "    gradiente = -(Y-U_V).T@U + lambda_*V\n",
    "    \n",
    "    return gradiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_na(X,Y):\n",
    "    \n",
    "    n,m = X.shape\n",
    "    lista = []\n",
    "    \n",
    "    for i in range(n):\n",
    "        pos_na = ~np.isnan(X[i,:])\n",
    "        lista.append(X[i,pos_na]@Y[pos_na])\n",
    "        lista_ = np.array(lista)\n",
    "    \n",
    "    return lista_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descenso_gradiente_U(Y,U,V,k,lambda_,eta,epsilon):\n",
    "    \n",
    "    U_ = U\n",
    "    \n",
    "    while True:\n",
    "        U_aux = U_\n",
    "        gradiente_u = gradiente_U(Y,U_,V,k,lambda_)\n",
    "        U_ = U_ - eta * gradiente_u\n",
    "        \n",
    "        if (np.linalg.norm(U_aux-U_))< epsilon:\n",
    "            break\n",
    "\n",
    "    return U_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descenso_gradiente_V(Y,U,V,k,lambda_,eta,epsilon):\n",
    "    \n",
    "    V_ = V\n",
    "    \n",
    "    while True:\n",
    "        V_aux = V_\n",
    "        gradiente_v = gradiente_V(Y,U,V_,k,lambda_)\n",
    "        V_ = V_ - eta * gradiente_v\n",
    "        \n",
    "        if (np.linalg.norm(V_aux-V_))< epsilon:\n",
    "            break\n",
    "\n",
    "    return V_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimizacion_alternada(Y,k,lambda_,eta,epsilon):\n",
    "    \"\"\"\n",
    "    Objetivo:\n",
    "    Realizar minimizacion alternada\n",
    "    \n",
    "    Insumo:\n",
    "    Y - Matriz a evaluar\n",
    "    k - Hiperparametro para obtimizar funcion de costo\n",
    "    lambda - Hiperparametro de regularizacion\n",
    "    eta - Tamaño de paso\n",
    "    epsilon - Criterio de paro\n",
    "    \n",
    "    Resultado:\n",
    "    U - Sentimiento general de cada usuario hacia las peliculas\n",
    "    V - Como cada una de las peliculas es percibidas por los usuarios\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    n,m = Y.shape\n",
    "    \n",
    "    Y = np.nan_to_num(Y)\n",
    "    \n",
    "    U = np.random.uniform(low = 0,high = (1/np.sqrt(k)),size = [n,k])\n",
    "    V = np.random.uniform(low = 0,high = (1/np.sqrt(k)),size = [m,k])\n",
    "    \n",
    "    #Optimizar U\n",
    "    U_final = descenso_gradiente_U(Y,U,V,k,lambda_,eta,epsilon)\n",
    "    \n",
    "    #Optimizar V\n",
    "    V_final = descenso_gradiente_V(Y,U_final,V,k,lambda_,eta,epsilon)\n",
    "    \n",
    "    return U_final,V_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos hacer la revisión con esta matriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.array([[5, np.nan, 7], \n",
    "              [1, 1, np.nan]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5., nan,  7.],\n",
       "       [ 1.,  1., nan]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "U_Y,V_Y = minimizacion_alternada(Y,k=2,lambda_=0.1,eta=0.01,epsilon=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5. nan  7.]\n",
      " [ 1.  1. nan]]\n",
      "[[4.99555020e+00 1.23184693e-03 6.99075292e+00]\n",
      " [9.31499723e-01 9.46896020e-01 3.29064521e-02]]\n",
      "0.09328441428865487\n"
     ]
    }
   ],
   "source": [
    "print(Y)\n",
    "print(U_Y@V_Y.T)\n",
    "print(np.linalg.norm(np.nan_to_num(Y)-U_Y@V_Y.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### En estos momentos no se consideró el procedimiento de tratamiento especial de los Nulos, ya que el programa tarda mucho tiempo en correr. Por ahora estamos considerando los registros nulos como 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Haremos la estimación para la información de las películas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "U_final,V_final = minimizacion_alternada(ratings_wide,k=10,lambda_=0.1,eta=0.01,epsilon=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.607151334803234\n"
     ]
    }
   ],
   "source": [
    "print(np.linalg.norm(np.nan_to_num(ratings_wide)-U_final@V_final.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validacion cruzada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Justificar la elección de k .\\\n",
    "Como hacer la validacion cruzada, como implementar el test:\\\n",
    "    *Ya estimamos el modelo bajo train, que se hace con el test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificaremos el valor del ndcg score para diferentes valores de k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "U_a,V_a = minimizacion_alternada(ratings_wide,k=5,lambda_=0.1,eta=0.01,epsilon=1e-3)\n",
    "U_b,V_b = minimizacion_alternada(ratings_wide,k=10,lambda_=0.1,eta=0.01,epsilon=1e-3)\n",
    "U_c,V_c = minimizacion_alternada(ratings_wide,k=15,lambda_=0.1,eta=0.01,epsilon=1e-3)\n",
    "U_d,V_d = minimizacion_alternada(ratings_wide,k=50,lambda_=0.1,eta=0.01,epsilon=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndcga = ndcg_score(np.nan_to_num(ratings_wide), U_a@V_a.T)\n",
    "ndcgb = ndcg_score(np.nan_to_num(ratings_wide), U_b@V_b.T)\n",
    "ndcgc = ndcg_score(np.nan_to_num(ratings_wide), U_c@V_c.T)\n",
    "ndcgd = ndcg_score(np.nan_to_num(ratings_wide), U_d@V_d.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>NDCG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.783511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0.889948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>0.986706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    k      NDCG\n",
       "0   5  0.783511\n",
       "1  10  0.889948\n",
       "2  15  0.986706\n",
       "3  50  1.000000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"k\":[5,10,15,50],\n",
    "             \"NDCG\":[ndcga,ndcgb,ndcgc,ndcgd]})\n",
    "#[ndcg_score(np.nan_to_num(ratings_wide), U_5@V_5.T)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 Mejores recomendaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como hacer las recomendaciones para las 5 peliculas por usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "recomendation_matrix = U_final@V_final.T\n",
    "\n",
    "\n",
    "def recomendacion(user,recomendation_matrix,ratings_features,ratings_values):\n",
    "    rec_user = recomendation_matrix[user,]\n",
    "    ratings_user = ratings_values[user,]\n",
    "    \n",
    "    not_watched = pd.isnull([x for x in ratings_values[user,]])\n",
    "    rec_user[np.invert(not_watched)]=np.array([np.nan]*sum(np.invert(not_watched))) \n",
    "    \n",
    "    idx_top5=rec_user.argsort()[-5:][::-1]\n",
    "    print(\"Calificaciones: \",rec_user[idx_top5])\n",
    "    print(\"Puedes ver las películas: \",ratings_features[idx_top5])\n",
    "    return list(ratings_features[idx_top5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.43901655, -1.05332333, -1.05329247, -0.94796264, -0.94792357,\n",
       "       -0.94790737, -0.8941798 , -0.84264954, -0.84258877, -0.84257306,\n",
       "       -0.83269902, -0.71542291, -0.71529766, -0.70975145, -0.65865881,\n",
       "       -0.63200059, -0.59245806, -0.56168303, -0.53651635, -0.53650216,\n",
       "       -0.5348321 , -0.53091839, -0.53089469, -0.49278944, -0.45877199,\n",
       "       -0.45876059, -0.45867333, -0.39975307, -0.37010071, -0.37007304,\n",
       "       -0.37005048, -0.36705717, -0.36704267, -0.36695833, -0.3669413 ,\n",
       "       -0.35770487, -0.32903443, -0.32892995, -0.29354198, -0.29297594,\n",
       "       -0.2929108 , -0.28780838, -0.28775599, -0.27525604, -0.27522969,\n",
       "       -0.27521648, -0.2751345 , -0.27019345, -0.25256748, -0.24668872,\n",
       "       -0.23440356, -0.23439227, -0.2343814 , -0.23437804, -0.23432914,\n",
       "       -0.234326  , -0.22938833, -0.18366447, -0.18362753, -0.18356816,\n",
       "       -0.18354837, -0.17580194, -0.17579715, -0.17574809, -0.17322637,\n",
       "       -0.17286712, -0.13774037, -0.13771212, -0.13769242, -0.13764736,\n",
       "       -0.13729453, -0.09180244, -0.09177542, -0.05856631, -0.04594778,\n",
       "       -0.04593355, -0.04589893,  0.00919843,  0.02092369,  0.03074812,\n",
       "        0.03135007,  0.03143694,  0.04454215,  0.0468376 ,  0.06142477,\n",
       "        0.06146214,  0.06148805,  0.06150844,  0.06156814,  0.07016335,\n",
       "        0.07389223,  0.08443251,  0.09219107,  0.09228882,  0.09856409,\n",
       "        0.0985939 ,  0.10493291,  0.11261711,  0.11266107,  0.11271041,\n",
       "        0.12286359,  0.12291653,  0.12292824,  0.12294258,  0.12294701,\n",
       "        0.12295376,  0.12295868,  0.12296677,  0.12298156,  0.12299987,\n",
       "        0.12302616,  0.12673887,  0.12674613,  0.13352099,  0.14085742,\n",
       "        0.15021062,  0.15030486,  0.15372245,  0.15374378,  0.15376076,\n",
       "        0.17265898,  0.1779841 ,  0.17800168,  0.17800447,  0.17803679,\n",
       "        0.17809342,  0.17813103,  0.18434477,  0.18438164,  0.18438717,\n",
       "        0.18439827,  0.18440229,  0.18441885,  0.18443026,  0.18443062,\n",
       "        0.18444419,  0.18445482,  0.1844622 ,  0.18446899,  0.18447601,\n",
       "        0.18447692,  0.18448252,  0.18449364,  0.18449515,  0.18450094,\n",
       "        0.18453515,  0.18453554,  0.18772215,  0.1878081 ,  0.21511328,\n",
       "        0.2151214 ,  0.21516099,  0.21516512,  0.21518755,  0.21519671,\n",
       "        0.21522605,  0.21526851,  0.21528837,  0.21553546,  0.22180569,\n",
       "        0.2224738 ,  0.22252512,  0.22253051,  0.22254165,  0.22254781,\n",
       "        0.22255676,  0.2225809 ,  0.22258274,  0.22258503,  0.22261087,\n",
       "        0.2226148 ,  0.22262224,  0.22265356,  0.22266604,  0.22529413,\n",
       "        0.22529618,  0.22532083,  0.22534307,  0.22542032,  0.24585939,\n",
       "        0.24586554,  0.24586561,  0.2458797 ,  0.24587992,  0.24588372,\n",
       "        0.24588495,  0.24589173,  0.24589512,  0.24589761,  0.24590134,\n",
       "        0.24591684,  0.24591861,  0.24594052,  0.24594556,  0.24595632,\n",
       "        0.24595963,  0.2459781 ,  0.2460158 ,  0.24603202,  0.25884084,\n",
       "        0.26286996,  0.26287468,  0.26287678,  0.26294956,  0.26376611,\n",
       "        0.27091164,  0.27349525,  0.27660157,  0.27666101,  0.27667279,\n",
       "        0.29577948,  0.29579964,  0.3004611 ,  0.30050506,  0.30050549,\n",
       "        0.30732621,  0.30732686,  0.3074065 ,  0.30741279,  0.3074197 ,\n",
       "        0.30742858,  0.30743578,  0.30744295,  0.30745608,  0.30745958,\n",
       "        0.31969372,  0.32917951,  0.33611132,  0.33792722,  0.33798109,\n",
       "        0.33804427,  0.3380658 ,  0.3455637 ,  0.34558499,  0.34667783,\n",
       "        0.3596006 ,  0.36244141,  0.36307022,  0.37288491,  0.37555051,\n",
       "        0.37555306,  0.37555364,  0.37558092,  0.37559211,  0.37561315,\n",
       "        0.37628216,  0.37945297,  0.38185445,  0.38584203,  0.38958762,\n",
       "        0.3932803 ,  0.40589257,  0.40690393,  0.40693382,  0.44441921,\n",
       "        0.44449194,  0.45895869,  0.46837282,  0.46845618,  0.46847458,\n",
       "        0.48158971,  0.486415  ,  0.49272072,  0.49903861,  0.51701376,\n",
       "        0.51837277,  0.5183946 ,  0.53904468,  0.54711417,  0.54717063,\n",
       "        0.54717247,  0.56005633,  0.57032724,  0.57081462,  0.57246427,\n",
       "        0.60323776,  0.63835957,  0.64550068,  0.64875258,  0.66469582,\n",
       "        0.67013767,  0.67387528,  0.7295292 ,  0.72957723,  0.73697305,\n",
       "        0.76130145,  0.76888465,  0.76890113,  0.79306258,  0.8100591 ,\n",
       "        0.81452175,  0.82081912,  0.82573033,  0.94477974,  0.9957302 ,\n",
       "               inf,         inf,         inf,         inf,         inf,\n",
       "               inf,         inf,         inf,         inf,         inf,\n",
       "               inf,         inf,         inf,         inf,         inf,\n",
       "               inf,         inf,         inf,         inf,         inf,\n",
       "               inf,         inf,         inf,         inf,         inf,\n",
       "               inf,         inf,         inf,         inf,         inf,\n",
       "               inf,         inf,         inf,         inf,         inf,\n",
       "               inf,         inf,         inf,         inf,         inf,\n",
       "               inf,         inf,         inf,         inf,         inf,\n",
       "               inf,         inf,         inf,         inf,         inf,\n",
       "               inf,         inf,         inf,         inf,         inf,\n",
       "               inf,         inf,         inf,         inf,         inf,\n",
       "               inf,         inf,         inf,         inf,         inf,\n",
       "               inf,         inf,         inf,         inf,         inf,\n",
       "               inf,         inf,         inf,         inf,         inf,\n",
       "               inf,         inf,         inf,         inf,         inf,\n",
       "               inf,         inf,         inf,         inf,         inf,\n",
       "               inf,         inf,         inf,         inf,         inf,\n",
       "               inf,         inf,         inf,         inf,         inf,\n",
       "               inf,         inf,         inf,         inf,         inf,\n",
       "               inf,         inf,         inf,         inf,         inf,\n",
       "               inf,         inf,         inf,         inf,         inf,\n",
       "               inf,         inf,         inf,         inf,         inf,\n",
       "               inf,         inf,         inf,         inf,         inf,\n",
       "               inf,         inf,         inf,         inf,         inf,\n",
       "               inf,         nan,         nan,         nan,         nan,\n",
       "               nan,         nan,         nan,         nan,         nan,\n",
       "               nan,         nan,         nan,         nan,         nan,\n",
       "               nan,         nan,         nan,         nan,         nan,\n",
       "               nan,         nan,         nan,         nan,         nan,\n",
       "               nan,         nan,         nan,         nan,         nan,\n",
       "               nan,         nan,         nan,         nan,         nan,\n",
       "               nan,         nan,         nan,         nan,         nan,\n",
       "               nan,         nan,         nan,         nan,         nan,\n",
       "               nan,         nan,         nan,         nan,         nan,\n",
       "               nan,         nan,         nan,         nan,         nan,\n",
       "               nan,         nan,         nan,         nan,         nan,\n",
       "               nan,         nan,         nan,         nan,         nan,\n",
       "               nan,         nan,         nan,         nan,         nan,\n",
       "               nan,         nan,         nan,         nan,         nan,\n",
       "               nan,         nan,         nan,         nan,         nan,\n",
       "               nan,         nan,         nan,         nan,         nan,\n",
       "               nan,         nan,         nan,         nan,         nan,\n",
       "               nan,         nan,         nan,         nan,         nan,\n",
       "               nan,         nan,         nan,         nan,         nan,\n",
       "               nan,         nan,         nan,         nan,         nan,\n",
       "               nan,         nan,         nan,         nan,         nan,\n",
       "               nan,         nan,         nan,         nan,         nan,\n",
       "               nan,         nan,         nan,         nan,         nan,\n",
       "               nan,         nan,         nan,         nan,         nan,\n",
       "               nan,         nan,         nan,         nan,         nan,\n",
       "               nan,         nan,         nan,         nan,         nan,\n",
       "               nan,         nan,         nan,         nan,         nan,\n",
       "               nan,         nan,         nan,         nan,         nan,\n",
       "               nan,         nan,         nan,         nan,         nan,\n",
       "               nan,         nan,         nan,         nan,         nan,\n",
       "               nan,         nan,         nan,         nan,         nan,\n",
       "               nan,         nan,         nan,         nan,         nan,\n",
       "               nan,         nan,         nan,         nan,         nan,\n",
       "               nan,         nan,         nan,         nan,         nan,\n",
       "               nan,         nan,         nan,         nan,         nan,\n",
       "               nan,         nan,         nan,         nan,         nan,\n",
       "               nan,         nan,         nan,         nan,         nan,\n",
       "               nan,         nan,         nan,         nan,         nan,\n",
       "               nan,         nan,         nan,         nan,         nan,\n",
       "               nan,         nan,         nan,         nan,         nan,\n",
       "               nan,         nan,         nan,         nan,         nan,\n",
       "               nan,         nan,         nan,         nan,         nan,\n",
       "               nan,         nan,         nan,         nan,         nan,\n",
       "               nan,         nan,         nan,         nan,         nan,\n",
       "               nan,         nan,         nan,         nan,         nan,\n",
       "               nan,         nan,         nan,         nan,         nan,\n",
       "               nan,         nan,         nan,         nan,         nan,\n",
       "               nan,         nan,         nan,         nan,         nan,\n",
       "               nan,         nan,         nan,         nan,         nan,\n",
       "               nan,         nan,         nan,         nan,         nan,\n",
       "               nan,         nan,         nan,         nan,         nan,\n",
       "               nan,         nan,         nan,         nan,         nan,\n",
       "               nan,         nan,         nan,         nan,         nan,\n",
       "               nan,         nan,         nan,         nan,         nan,\n",
       "               nan,         nan,         nan,         nan,         nan,\n",
       "               nan,         nan,         nan,         nan,         nan,\n",
       "               nan,         nan,         nan,         nan,         nan,\n",
       "               nan,         nan,         nan,         nan,         nan,\n",
       "               nan,         nan,         nan,         nan,         nan,\n",
       "               nan,         nan,         nan,         nan,         nan,\n",
       "               nan,         nan,         nan,         nan,         nan,\n",
       "               nan,         nan,         nan,         nan,         nan,\n",
       "               nan])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user=6\n",
    "rec_user = recomendation_matrix[user,]\n",
    "ratings_user = ratings_values[user,]\n",
    "\n",
    "not_watched = pd.isnull([x for x in ratings_values[user,]])\n",
    "#rec_user[np.invert(not_watched)]=np.array([np.inf]*sum(np.invert(not_watched))) \n",
    "\n",
    "idx_top5=rec_user.argsort()[-5:][::-1]\n",
    "rec_user.argsort()[-5:][::-1]\n",
    "rec_user.sort()\n",
    "rec_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de Usuario :6\n",
      "Calificaciones:  [nan nan nan nan nan]\n",
      "Puedes ver las películas:  [ 380 1231 1198 1210 1220]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[380, 1231, 1198, 1210, 1220]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user = int(input(\"Número de Usuario :\"))\n",
    "recomendacion(user,recomendation_matrix,ratings_features,ratings_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pendientes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agregar más teoría al documento"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
