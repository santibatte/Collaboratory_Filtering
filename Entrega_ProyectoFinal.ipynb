{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Integrantes\n",
    "* Santiago\n",
    "* Jose\n",
    "* Patricia\n",
    "* Yedam Fortiz 119523"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de paqueteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import random as r\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import ndcg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de Informacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = pd.read_csv(\"links_small.csv\")\n",
    "ratings = pd.read_csv(\"ratings_small.csv\")\n",
    "ratings = ratings.drop(\"timestamp\",axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Por ahora consideraremos únicamente 1500 lineas de ratings, no los 100,000 registros ya que el algoritmo no está optimizado para una base de datos tan grande"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test = train_test_split(ratings.head(1500),test_size=0.3,random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_wide = X_train.pivot_table(index = 'userId',\n",
    "                                   columns = 'movieId',\n",
    "                                   values = 'rating')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creacion de matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "links_values = np.array(links)\n",
    "links_features = np.array(links.columns)\n",
    "ratings_values = np.array(ratings_wide)\n",
    "ratings_features = np.array(ratings_wide.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funcion de costo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\large J(X)  =  \\frac{1}{2} \\sum_{(a,i \\in D)} (Y_{ai} - [UV^T]_{ai} )^2 + \\frac{\\lambda}{2} \\sum_{a=1}^n\\sum_{j=1}^k U_{aj}^2 + \\frac{\\lambda}{2} \\sum_{i=1}^m\\sum_{j=1}^k V_{ij}^2  $$\n",
    "\n",
    "* Seleccionamos $V$ al azar y la dejamos fija y optimizamos con respecto a $U$\n",
    "* Una vez actualizada la $U$, la dejamos fija y optimizamos con respecto a $V$\n",
    "* Repetimos hasta que converja (variaciones entre las estimaciones de los vectores es pequeña) (optimo local)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Minimizacion Alternada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradiente_U (Y,U,V,k,lambda_):\n",
    "    \n",
    "    if k!=1:\n",
    "        U_V = U.dot(V.T)\n",
    "    else:\n",
    "        U_V = np.outer(U,V)\n",
    "    \n",
    "    na = np.isnan(Y)\n",
    "    \n",
    "    #Tratamiento especial NA\n",
    "    #gradiente = -dot_na(Y-U_V, V) + lambda_*U\n",
    "    gradiente = -(Y-U_V)@V + lambda_*U\n",
    "    \n",
    "    return gradiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradiente_V (Y,U,V,k,lambda_):\n",
    "    \n",
    "    if k!=1:\n",
    "        U_V = U.dot(V.T)\n",
    "    else:\n",
    "        U_V = np.outer(U,V)\n",
    "    \n",
    "    na = np.isnan(Y)\n",
    "    \n",
    "    #Tratamiento especial NA\n",
    "    #gradiente = -dot_na((Y-U_V).T, U) + lambda_*V\n",
    "    gradiente = -(Y-U_V).T@U + lambda_*V\n",
    "    \n",
    "    return gradiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_na(X,Y):\n",
    "    \n",
    "    n,m = X.shape\n",
    "    lista = []\n",
    "    \n",
    "    for i in range(n):\n",
    "        pos_na = ~np.isnan(X[i,:])\n",
    "        lista.append(X[i,pos_na]@Y[pos_na])\n",
    "        lista_ = np.array(lista)\n",
    "    \n",
    "    return lista_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descenso_gradiente_U(Y,U,V,k,lambda_,eta,epsilon):\n",
    "    \n",
    "    U_ = U\n",
    "    \n",
    "    while True:\n",
    "        U_aux = U_\n",
    "        gradiente_u = gradiente_U(Y,U_,V,k,lambda_)\n",
    "        U_ = U_ - eta * gradiente_u\n",
    "        \n",
    "        if (np.linalg.norm(U_aux-U_))< epsilon:\n",
    "            break\n",
    "\n",
    "    return U_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descenso_gradiente_V(Y,U,V,k,lambda_,eta,epsilon):\n",
    "    \n",
    "    V_ = V\n",
    "    \n",
    "    while True:\n",
    "        V_aux = V_\n",
    "        gradiente_v = gradiente_V(Y,U,V_,k,lambda_)\n",
    "        V_ = V_ - eta * gradiente_v\n",
    "        \n",
    "        if (np.linalg.norm(V_aux-V_))< epsilon:\n",
    "            break\n",
    "\n",
    "    return V_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimizacion_alternada(Y,k,lambda_,eta,epsilon):\n",
    "    \"\"\"\n",
    "    Objetivo:\n",
    "    Realizar minimizacion alternada\n",
    "    \n",
    "    Insumo:\n",
    "    Y - Matriz a evaluar\n",
    "    k - Hiperparametro para obtimizar funcion de costo\n",
    "    lambda - Hiperparametro de regularizacion\n",
    "    eta - Tamaño de paso\n",
    "    epsilon - Criterio de paro\n",
    "    \n",
    "    Resultado:\n",
    "    U - Sentimiento general de cada usuario hacia las peliculas\n",
    "    V - Como cada una de las peliculas es percibidas por los usuarios\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    n,m = Y.shape\n",
    "    \n",
    "    Y = np.nan_to_num(Y)\n",
    "    \n",
    "    U = np.random.uniform(low = 0,high = (1/np.sqrt(k)),size = [n,k])\n",
    "    V = np.random.uniform(low = 0,high = (1/np.sqrt(k)),size = [m,k])\n",
    "    \n",
    "    #Optimizar U\n",
    "    U_final = descenso_gradiente_U(Y,U,V,k,lambda_,eta,epsilon)\n",
    "    \n",
    "    #Optimizar V\n",
    "    V_final = descenso_gradiente_V(Y,U_final,V,k,lambda_,eta,epsilon)\n",
    "    \n",
    "    return U_final,V_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos hacer la revisión con esta matriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.array([[5, np.nan, 7], \n",
    "              [1, 1, np.nan]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5., nan,  7.],\n",
       "       [ 1.,  1., nan]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "U_Y,V_Y = minimizacion_alternada(Y,k=2,lambda_=0.1,eta=0.01,epsilon=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5. nan  7.]\n",
      " [ 1.  1. nan]]\n",
      "[[ 4.99114292e+00 -1.49238422e-03  6.99200775e+00]\n",
      " [ 8.44586362e-01  9.28919502e-01 -9.37683960e-03]]\n",
      "0.1715759669644307\n"
     ]
    }
   ],
   "source": [
    "print(Y)\n",
    "print(U_Y@V_Y.T)\n",
    "print(np.linalg.norm(np.nan_to_num(Y)-U_Y@V_Y.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### En estos momentos no se consideró el procedimiento de tratamiento especial de los Nulos, ya que el programa tarda mucho tiempo en correr. Por ahora estamos considerando los registros nulos como 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Haremos la estimación para la información de las películas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "U_final,V_final = minimizacion_alternada(ratings_wide,k=10,lambda_=0.1,eta=0.01,epsilon=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47.91649305803306\n"
     ]
    }
   ],
   "source": [
    "print(np.linalg.norm(np.nan_to_num(ratings_wide)-U_final@V_final.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validacion cruzada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Justificar la elección de k .\\\n",
    "Como hacer la validacion cruzada, como implementar el test:\\\n",
    "    *Ya estimamos el modelo bajo train, que se hace con el test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificaremos el valor del ndcg score para diferentes valores de k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "U_a,V_a = minimizacion_alternada(ratings_wide,k=5,lambda_=0.1,eta=0.01,epsilon=1e-3)\n",
    "U_b,V_b = minimizacion_alternada(ratings_wide,k=10,lambda_=0.1,eta=0.01,epsilon=1e-3)\n",
    "U_c,V_c = minimizacion_alternada(ratings_wide,k=15,lambda_=0.1,eta=0.01,epsilon=1e-3)\n",
    "U_d,V_d = minimizacion_alternada(ratings_wide,k=50,lambda_=0.1,eta=0.01,epsilon=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndcga = ndcg_score(np.nan_to_num(ratings_wide), U_a@V_a.T)\n",
    "ndcgb = ndcg_score(np.nan_to_num(ratings_wide), U_b@V_b.T)\n",
    "ndcgc = ndcg_score(np.nan_to_num(ratings_wide), U_c@V_c.T)\n",
    "ndcgd = ndcg_score(np.nan_to_num(ratings_wide), U_d@V_d.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>NDCG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.718625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0.919949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>0.996974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    k      NDCG\n",
       "0   5  0.718625\n",
       "1  10  0.919949\n",
       "2  15  0.996974\n",
       "3  50  1.000000"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"k\":[5,10,15,50],\n",
    "             \"NDCG\":[ndcga,ndcgb,ndcgc,ndcgd]})\n",
    "#[ndcg_score(np.nan_to_num(ratings_wide), U_5@V_5.T)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 Mejores recomendaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como hacer las recomendaciones para las 5 peliculas por usuario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pendientes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agregar más teoría al documento"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
